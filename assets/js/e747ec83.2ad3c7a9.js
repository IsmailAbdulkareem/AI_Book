"use strict";(globalThis.webpackChunkphysical_ai_robotics_book=globalThis.webpackChunkphysical_ai_robotics_book||[]).push([[51],{3583:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"glossary","title":"Glossary","description":"This glossary defines key terms used throughout the Physical AI & Humanoid Robotics book. It will be maintained and extended as modules are written.","source":"@site/docs/glossary.md","sourceDirName":".","slug":"/glossary","permalink":"/AI_Book/docs/glossary","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"glossary","title":"Glossary","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Environment Setup","permalink":"/AI_Book/docs/introduction/intro-environment-setup"},"next":{"title":"Module 1: The Robotic Nervous System (ROS 2)","permalink":"/AI_Book/docs/module1/"}}');var o=s(4848),t=s(8453);const r={id:"glossary",title:"Glossary",sidebar_position:3},a="Glossary",l={},d=[{value:"A",id:"a",level:2},{value:"D",id:"d",level:2},{value:"G",id:"g",level:2},{value:"H",id:"h",level:2},{value:"I",id:"i",level:2},{value:"L",id:"l",level:2},{value:"N",id:"n",level:2},{value:"P",id:"p",level:2},{value:"R",id:"r",level:2},{value:"S",id:"s",level:2},{value:"T",id:"t",level:2},{value:"U",id:"u",level:2},{value:"V",id:"v",level:2}];function c(e){const n={em:"em",h1:"h1",h2:"h2",header:"header",hr:"hr",p:"p",strong:"strong",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"glossary",children:"Glossary"})}),"\n",(0,o.jsx)(n.p,{children:"This glossary defines key terms used throughout the Physical AI & Humanoid Robotics book. It will be maintained and extended as modules are written."}),"\n",(0,o.jsx)(n.h2,{id:"a",children:"A"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Action (ROS 2)"}),": A communication pattern in ROS 2 for long-running tasks with feedback. Actions combine the request-response pattern of services with the continuous data stream of topics."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"ASR (Automatic Speech Recognition)"}),": Technology that converts spoken language into text. Examples include OpenAI Whisper and Google Speech-to-Text."]}),"\n",(0,o.jsx)(n.h2,{id:"d",children:"D"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Digital Twin"}),": A virtual representation of a physical robot or system that mirrors its behavior in simulation. Used for development, testing, and training before deployment."]}),"\n",(0,o.jsx)(n.h2,{id:"g",children:"G"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Gazebo"}),": An open-source physics simulation engine for robotics. Supports realistic physics, sensor simulation, and robot modeling via URDF/SDF."]}),"\n",(0,o.jsx)(n.h2,{id:"h",children:"H"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Humanoid Robot"}),": A robot designed to resemble and move like a human, typically with a torso, head, two arms, and two legs. Examples include Unitree G1, Boston Dynamics Atlas."]}),"\n",(0,o.jsx)(n.h2,{id:"i",children:"I"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Isaac ROS"}),": NVIDIA's ROS 2 packages for perception, navigation, and manipulation. Includes VSLAM, object detection, and other AI-powered pipelines."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Isaac Sim"}),": NVIDIA's photorealistic robotics simulator built on Omniverse. Provides high-fidelity physics, graphics, and synthetic data generation."]}),"\n",(0,o.jsx)(n.h2,{id:"l",children:"L"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"LLM (Large Language Model)"}),": AI models trained on vast text corpora that can understand and generate natural language. Examples include GPT-4, Claude, LLaMA."]}),"\n",(0,o.jsx)(n.h2,{id:"n",children:"N"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Nav2"}),": The ROS 2 navigation stack for mobile robots. Provides path planning, obstacle avoidance, and localization capabilities."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Node (ROS 2)"}),": A process in ROS 2 that performs computation. Nodes communicate via topics, services, and actions."]}),"\n",(0,o.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Physical AI"}),': The intersection of artificial intelligence and embodied systems (robots) that exist in and interact with the physical world. Contrasts with "pure digital" AI that operates only in computational spaces.']}),"\n",(0,o.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 (Robot Operating System 2)"}),": The second generation of ROS, a middleware framework for building distributed robot systems. Provides communication, tools, and libraries for robotics development."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"ros2_control"}),": A ROS 2 framework for managing robot hardware interfaces, controllers, and real-time control loops."]}),"\n",(0,o.jsx)(n.h2,{id:"s",children:"S"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"SDF (Simulation Description Format)"}),": An XML format for describing robots, sensors, and environments in Gazebo. More feature-rich than URDF."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Service (ROS 2)"}),": A request-response communication pattern in ROS 2. A client sends a request and waits for a response from a server."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Sim-to-Real Transfer"}),": The process of training AI models or developing behaviors in simulation and successfully deploying them to physical robots."]}),"\n",(0,o.jsx)(n.h2,{id:"t",children:"T"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"TF2 (Transform Library)"}),": A ROS 2 library for tracking coordinate frame relationships over time. Essential for robot kinematics and sensor fusion."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Topic (ROS 2)"}),": A named communication channel in ROS 2 where nodes publish and subscribe to messages. Uses a publish-subscribe pattern."]}),"\n",(0,o.jsx)(n.h2,{id:"u",children:"U"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"URDF (Unified Robot Description Format)"}),": An XML format for describing robot structure, joints, and links. Used by ROS 2 and Gazebo for robot modeling."]}),"\n",(0,o.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"VLA (Vision-Language-Action)"}),": A robotics paradigm that combines computer vision, natural language understanding, and robot action execution. Enables robots to follow natural language commands."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"VSLAM (Visual Simultaneous Localization and Mapping)"}),": A technique that uses camera data to simultaneously build a map of the environment and determine the robot's position within it."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"This glossary is a living document and will be updated as new concepts are introduced throughout the book."})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>a});var i=s(6540);const o={},t=i.createContext(o);function r(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);